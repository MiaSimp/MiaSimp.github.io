<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Data Science Tutorial</title>
  <style>
    body {
      font-family: Courier(monospace);
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: flex-start;
      height: 100vh;
      background-color: #DFD7DB; /* Light pink background */
    }
    .container {
      width: 60%; /* width of container*/
      text-align: center;
      background-color: white; /* Background color for the content area */
      padding: 40px;
      border-radius: 8px; /* Rounded corners for the content area */
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); /* Box shadow for a subtle lift */
      margin: 20px 0; /* Margin to center the container */
  
    }
    .name {
      font-size: 1.5rem;
      margin-bottom: 10px;
      border-bottom: 2px solid #DFD7DB; /* Pink border bottom */
      padding-bottom: 10px; /* Space between title and line */
    }
    .title {
      font-size: 2.5rem;
      margin-bottom: 20px;
    }
    .body-text {
      font-size: 1.0rem;
      text-align: left; /* Align the body text to the left */
      line-height: 1.6; /* Adjust line height for better readability */
    }
  </style>
</head>
<body>
  <div class="container">
    <h1 class="title">Predicting the Genres of Hulu TV Shows</h1>
    <p class="name">Mia Simpson</p>
    <h2 class = "body-text">Introduction</h2>
    <p class = "body-text"> This tutorial utilizes the Machine Learning algorithm of Multinomial Naive Bayes to predict TV show genres based on titles and plot summaries. The Multinomial Naive Bayes algorithm is seen mostly in Natural Language Processing and uses the Bayes’ theorem to predict the category of a text. 
	    The classifier operates by calculating the probability of an object belonging to a certain category based on the probabilities of its features occurring in that category, assuming that the features of the data are independent of each other. The category with the highest calculated probability is then selected as 
	    the predicted classification for your given object. <br><br>
	    In this tutorial, we will be predicting the genre of a TV show based on the text in its title and description. TV show genres are typically manually tagged, which can be a tedious process when taking into account how many shows exist on platforms such as Hulu. Since summaries and titles hold integral information about their shows, 
	    I employed this Machine Learning algorithm to quickly classify TV show genres given their title and description. 
</p>
    <h2 class = "body-text">Data Gathering</h2>
	<p class = "body-text">Before we get into the steps of creating and testing our classification model, we must import all of the libraries that we will use throughout the program. </p>
	  <div class="body-text"> 
	  <script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L1-L9&style=base16%2Focean&type=code&showFullPath=on"></script> 

	  </div>
    <p class = "body-text">The first step in this process is to gather the data that will be used in our algorithm. For this tutorial, we are using a dataset from Kaggle, as it contains a list of data for the top 109 TV shows from the Hulu streaming service. This dataset contains the plot summaries and genres of each TV show, and will work perfectly to demonstrate our classification algorithm. The dataset is in csv format and after downloading the file from Kaggle, we can load it into a pandas dataframe for later manipulation and analysis of the data. 
	<br>Download the dataset here: </p>
	  <div class="body-text">
	<a href="https://www.kaggle.com/datasets/thedevastator/hulu-popular-shows-dataset">TV Show Dataset</a>
	  <script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L85-L86&style=base16%2Focean&type=code&showFullPath=on"></script>
	</div>
	<p class = "body-text">While we did not require web scraping to acquire our dataset, this technique of data gathering is instrumental in the data science field for fetching information from online resources. Web scraping involves the automated extraction of unstructured data from web pages and storing them in an structured format. Web scraping software retrieves the HTML code of a website and parses through it to gather data that fits predetermined parameters. Once the data is found, the web scraper downloads and structures the data so that you may use it for later analysis. Web scraping enables access to diverse data sets, and in similar projects, it could look like scraping various TV show related websites to compile extensive data on even more shows than are represented in our dataset. 
	 </p>
    <h2 class = "body-text">Data Ethics</h2>
    	<p class = "body-text"> Now that we have gathered our data, we can touch on data ethics. Ethical data collection is integral in any project that involves data analysis. Data ethics refers to collecting and analyzing data in moral and responsible ways. Whether intentional or unintentional, poorly collected data can be used to perpetuate biases or misinterpreted the reality of a situation. It is necessary to ensure that your data is gathered ethically to protect the personally identifiable data of individuals, avoid implicit bias, and ensure that the data is true and trustworthy. Upon collecting your data, you should consider the potential societal implications and privacy concerns related to it. Machine learning algorithms, including the one we are using here, have the potential to benefit the efficiency, consistency, speed, and cost of jobs, if implemented properly and ethically, so approaching them with good intentions is very important. When not approached ethically, data collection can introduce inaccuracies and skewed perspectives into your machine learning algorithm due to bias, measurement error, and/or incomplete samples. This may reinforce or even amplify biases within the models and analyses you create. To address these issues by modeling proper data ethics in your programs is vital in ensuring its fair and correct results.
<br><br>When we collect our data we need to ensure that the data is collected legally by checking the terms of service and ensuring that you do not need to make an account to access the website. If you need to login to access the data, or the terms of service of the site state that web scraping is not allowed, you cannot collect data from that site. You should also make sure that you do not violate copyright laws or the Computer Fraud and Abuse Act with your use of the data. Furthermore, if you are web scraping and negatively impact someone’s website with the intent to harm, you are trespassing to chattel, which is another unethical method of data gathering and use. 
<br><br>Both the gathering and use of data can be unethical, whether intentional or unintentional, so it is imperative to keep data ethics in mind to ensure the proper usage of data. 
</p>
    <h2 class = "body-text">Munging, Wrangling, and Cleaning Data</h2>

	<p class = "body-text"> The next step in our process is to transform and clean our data to be analyzed. This involves data munging, wrangling, and cleaning. While our dataset did not need extensive cleaning or transforming, the data preparation stage is still pivotal in data science, taking up 80% or more of an analyst’s time. 

<br><br>For data preparation, we convert the dataset from its raw, messy form into a higher quality, more usable format. Some transformations that may be needed are standardizing formats and handling missing, irrelevant, unnecessary, and inconsistent data. For many data science projects, the data will come with inconsistencies that require cleaning to be later analyzed with any sort of accuracy. For example, in our case, the dataset came with 1000 entries, but there were only 109 unique entries. This means that we need to clean the data of duplicate entries. This plays an important role in ensuring the integrity of the dataset and preventing skewed results.  Furthermore, to focus on only the core elements necessary for our analysis, we can reduce the columns in our dataset. Given the objective of the classification algorithm, we can isolate just the show name, description, and genre columns. This filtering of the dataset to only include specific attributes streamlines our analysis process, while discarding unnecessary information that did not contribute to our model. Here we can see how to isolate the necessary columns and drop the duplicates. 
	</p>
	  <div class="body-text">
	  <script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L88-L95&style=base16%2Focean&type=code&showFullPath=on"></script>
	  </div>
<div class="body-text">
<h2>Analysis</h2>
<p>The Multinomial Naive Bayes algorithm is a probabilistic algorithm that we use in text categorization. In this project, we are using this algorithm to predict TV show genres. The theory behind the algorithm lies in the assumption that there is independence between features and the calculation of conditional probabilities. The features in our algorithm are the show titles and descriptions, due to their importance in defining the genre of a show. The Multinomial Naive Bayes algorithm is based on the Bayes theorem. The Bayes theorem calculates the probability of an event occurring,  given prior information about the conditions relating to the event. The formula of the theorem is: P(A|B) = P(A) * P(B|A) / P(B), where P(B) is the prior probability of B, P(A) is the prior probability of category A, and P(B|A) is the probability of B given A. With this information, we can use the formula to calculate the probability of a show belonging to each category, and the category with the highest probability is the resulting prediction. In our calculations, P(A|B) will be the probability of the genre given the word, P(A) will be the probability of the genre, P(B) will be the probability of the word occurring in the category, and P(B|A) will be the probability of the word given the genre.We also employ laplace smoothing in our algorithm to prevent probabilities of 0 when words did not show up in the training data, but do show up in the testing data. To do this, we add one to every count so they are never 0, and then we add the number of possible words to the divisor. In terms of variables, I chose to implement the Multinomial Classification Algorithm with the variables of the title and description as features because of their significance in defining the genre of a show. Plot descriptions provide vital information for determining what the show is about, thus they provide enough information to ascertain a genre. 
<br><br> These histograms display the top 10 word frequencies in the comedy and drama genres. They give us a depiction of the assumption that the Naive Bayes Algorithm makes of feature independence. By showcasing the most prevalent words in each of these genres, we can see the distinct patterns that categorize a show into a particular genre. For example, we can see in the Drama histogram that words like "drama," "award," or "chicago" dominate, reflecting the thematic elements that are central to this genre. In the Comedy genre, on the other hand, frequent occurrences of words like "series," "family," or “comedy” signify that it is its own distinct category with different identifying characteristics. The Naive Bayes algorithm we are creating relies on these distinctive word frequencies, assuming their independence, to make predictions of genres. These histograms represent the crucial role that these features play in the algorithm’s decision making process. 

<br><br>These histograms also hint at the impact that Laplace smoothing makes on the word frequencies. Absent words in the training set, when encountered in the testing set, would have a minimum frequency of one, given our Laplace smoothing. This ensures that these absent words also contribute to the calculation of probabilities, avoiding probabilities of 0. Overall, these visualizations of data tell us how Naive Bayes utilizes distinct word frequencies and their independence from each other to predict the genres of TV shows when given their titles and plot summaries. 
<br><br>Below is the code for the function to create histograms for each category, as well as how to call it. 
</p>
<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L16-L57&style=base16%2Focean&type=code&showFullPath=on"></script>
<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L282&style=base16%2Focean&type=code&showFullPath=on"></script>		  
 
<p>Getting into the code, we can start by creating a function to filter your title and description to be tokenized and free of all stopwords.  </p>
	<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L61-L83&style=base16%2Focean&type=code&showFullPath=on"></script>
<p>Read in this text file of an extensive list of stopwords. 
	<br><p>I obtained the stopwords.txt file from this source: </p>
	<a href="https://github.com/stopwords-iso/stopwords-en/blob/master/stopwords-en.txt">Stopwords</a>
	<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L114-L125&style=base16%2Focean&type=code&showFullPath=on"></script>
<p>Separate out your training and testing data. 80% of the dataset will go into training data and 20% will go into testing data. You partition it out in this way to ensure that there is proper representation in the model, while keeping enough data to properly test the model. The training data will be used to estimate the probabilities for classification, while the testing data will be used to evaluate the model’s performance. 
</p>
	<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L98-L112&style=base16%2Focean&type=code&showFullPath=on"></script>
<p>Find the probabilities for each word for each genre, be sure to include laplace smoothing. I use dictionaries to hold the word counts, category counts, and word probabilities. This is because they utilize key-value pairs, making it easy to find data. We can begin by iterating through the training data and for each object, take the title and description as one and filter it. Then the program counts the occurrences of all of the words in total, as well as in each category. We also make note of the category occurrences. Then we can calculate the probabilities of each word in each category. We do this by calculating the probability of the current category in the loop, and then calculate the probability of the words, multiplying them with that original category probability. Once the probability of the category is calculated, we add it to the dictionary for word probabilities in the current category. 
</p>
	<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L133-L181&style=base16%2Focean&type=code&showFullPath=on"></script>
<p>Now that we have used the training data to calculate the probability of each word being in each category, we can test our model. To do this we calculate the probability that a show in the testing data set is part of each genre, be sure to include laplace smoothing. First we loop through the testing dataset and filter the combined title and show description to be a filtered list. With this list, we loop through each category to calculate the probability of the category and that each word in the list is in that category, multiplying them together. This results in the probability that the show is in the category. This repeats for each category and we append all probabilities to a list. Once all probabilities are calculated, we append to our results dictionary the actual genre of the show, as well as the genre with the highest calculated probability. The entire testing dataset is categorized in this manner. 
</p>
	<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L185-L227&style=base16%2Focean&type=code&showFullPath=on"></script>
<p>Now, we calculate the accuracy of our classification model. We do this by counting the total guesses, the total guesses in each category, the correct guesses in each category, and the total correct guesses. We do this by iterating through the results dictionary and comparing the actual and predicted genres. Finally we divide the correct guesses by the total number of guesses for all categories, as well as for each individual category. We create a new dictionary here to hold the accuracy calculations for each category. An important note is that if the category does not occur in our testing data, we set the accuracy to 0. 
</p>
	<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L232-L271&style=base16%2Focean&type=code&showFullPath=on"></script>		  
<p>Finally, we print our results. </p>
	<script src="https://emgithub.com/embed-v2.js?target=https%3A%2F%2Fgithub.com%2FMiaSimp%2Fclassifier%2Fblob%2Fmain%2Fproject3.py%23L275-L279&style=base16%2Focean&type=code&showFullPath=on"></script>  
<br>
	<p>My results were: <br>
<ul>
<li>Overall Accuracy: 61.90%</li>
<li>Category-wise Accuracy:</li>
<li>Kids: 50.00%</li>
<li>Drama: 80.00%</li>
<li>Animation and Cartoons: 0.00%</li>
<li>Comedy: 63.64%</li>
<li>Anime: 100.00%</li>
<li>Reality and Game Shows: 0.00%</li>
<li>Classics: 0.00%</li>
<li>Family: 0.00%</li>
<li>Science Fiction: 0.00%</li>
<li>Action and Adventure: 0.00%</li>
<li>Food: 0.00%</li>
<li>News and Information: 0.00%</li>
<li>Health and Wellness: 0.00%</li>
<li>Teen: 0.00%</li>
</ul>
<br>
This means that the overall accuracy of the classifier was 61.9%, which suggests that the classifier performs better than random guessing but definitely has a lot of room for improvement. Some methods of improving the classifier include expanding the dataset to include more than just 109 shows. This will give you a lot more data to work with and allow for proper representation of each genre in the training and testing sets. Since not all of the categories were represented in the dataset, we do not get true accuracy results for many of the genres, such as classics and family. Looking at the category accuracies, it looks like the accuracy for most is 0, but that is simply because they were not represented in the dataset. The actual list of represented categories it: 
Category-wise Accuracy: <br>
<ul>
<li>Kids: 50.00%</li>
<li>Drama: 80.00%</li>
<li>Animation and Cartoons: 0.00%</li>
<li>Comedy: 63.64%</li>
<li>Anime: 100.00%</li>
</ul>
<br>Looking at this, we can see that the accuracy was generally above 50% in terms of accuracy, where only one category is 0% where no shows in that genre were correctly categorized. As mentioned above, the model would be greatly improved with a larger dataset so that all genres could be represented in the testing set. 

<br>Overall, this model had an accuracy of over 50% for its categorization of TV show genres, given their titles and plot summaries. Although this is better than random guessing, it leaves a lot of room for improvement. We can see that the title and summary give enough information to categorize TV shows, but you definitely need a large data pool to be able to accurately categorize them by genre with a good level of accuracy. 
</p>
  </div>
  </div>
</body>
</html>
